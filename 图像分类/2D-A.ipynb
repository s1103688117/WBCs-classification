{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 778.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 794.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 693.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 783.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 777.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "epochs = 17\n",
    "batch_size = 2\n",
    "output_dir = r'E:\\2D_A_Result'\n",
    "patience =5\n",
    "\n",
    "#####TO GET IMAGE DATA\n",
    "from skimage.external.tifffile import imread\n",
    "from tqdm import tqdm\n",
    "def get_data(folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for cell_type in os.listdir(folder):\n",
    "        if not cell_type.startswith('.'):\n",
    "            if cell_type in ['E']:\n",
    "                label = 1\n",
    "                label2 = 1\n",
    "            elif cell_type in ['L']:\n",
    "                label = 2\n",
    "                label2 = 2\n",
    "            elif cell_type in ['M']:\n",
    "                label = 3\n",
    "                label2 = 3\n",
    "            elif cell_type in ['N']:\n",
    "                label = 4\n",
    "                label2 = 4\n",
    "            elif cell_type in ['B']:\n",
    "                label = 0\n",
    "                label2 = 0\n",
    "            for pro_name in tqdm(os.listdir(folder +'/'+ cell_type)):\n",
    "                img_data= imread(folder + '/'+cell_type + '/' + pro_name)\n",
    "                if img_data is not None:\n",
    "                    X.append(img_data)\n",
    "                    y.append(label)\n",
    "                    z.append(label2)\n",
    "\n",
    "\n",
    "#     X = np.asarray(X)\n",
    "    X = np.asarray(X)/255\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    return X,y,z\n",
    "\n",
    "###To get image\n",
    "data_path = r'F:\\image\\IMAGES'\n",
    "x_img_16, y_img_16, z_img_16 = get_data(data_path)\n",
    "train_index_path = r'C:\\Users\\东\\Desktop\\train1.csv'\n",
    "test_index_path = r'C:\\Users\\东\\Desktop\\test1.csv'\n",
    "train_index=pd.read_csv(train_index_path)['0'].values.astype(np.int)\n",
    "test_index=pd.read_csv(test_index_path)['0'].values.astype(np.int)\n",
    "x_img_train=x_img_16[train_index]\n",
    "x_img_test=x_img_16[test_index]\n",
    "y_img_train=y_img_16[train_index]\n",
    "y_img_test=y_img_16[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###建立模型\n",
    "import torch.nn.functional as f\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 2 attention modules.\n"
     ]
    }
   ],
   "source": [
    "def build_softmax_module(input_channels):\n",
    "    return torch.nn.Sequential(\n",
    "                                torch.nn.Conv2d(in_channels=input_channels,out_channels =1,kernel_size=1),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Softmax(dim=2)\n",
    "                                )\n",
    "\n",
    "def build_classifier_confidence(input_channels):\n",
    "\n",
    "    return torch.nn.Sequential(\n",
    "                                torch.nn.Linear(input_channels,256),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Linear(256,1),\n",
    "                                torch.nn.Tanh()\n",
    "                                )\n",
    "\n",
    "\n",
    "class AttentionBlock(torch.nn.Module):\n",
    "    def __init__(self, input_channels, input_dimension, num_classes):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self._softmax_block_1 = build_softmax_module(input_channels)\n",
    "        self._confidence_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dimension, 1),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "        self._attention_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dimension, num_classes)\n",
    "        )\n",
    "\n",
    "        self._attention_heatmaps = [[] for _ in range(num_classes)] #返回num_calsses个空列表\n",
    "\n",
    "    def forward(self,z:torch.Tensor,y:torch.Tensor,infer:bool):\n",
    "        heatmap = self._softmax_block_1(z)\n",
    "\n",
    "        if infer:\n",
    "            for i, class_ in enumerate(y):\n",
    "                self._attention_heatmaps[torch.argmax(class_)].append(heatmap[i])\n",
    "        cross_product = torch.einsum(\"ijkm,ilkm->ijlkm\", (heatmap.clone(), z.clone())) \\\n",
    "            .reshape(heatmap.shape[0], -1,heatmap.shape[2], heatmap.shape[3])\n",
    "        cross_product = f.avg_pool2d(cross_product.permute(0,3,2,1),(cross_product.shape[2],cross_product.shape[1]))\n",
    "        cross_product = cross_product.squeeze()\n",
    "        return self._attention_net(cross_product) * self._confidence_net(cross_product)\n",
    "\n",
    "from torch.nn import functional as F\n",
    "class RestNetBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(RestNetBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = F.relu(self.bn1(output))\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        return F.relu(x + output)\n",
    "\n",
    "\n",
    "class RestNetDownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(RestNetDownBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride[0], padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride[1], padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.extra = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride[0], padding=0),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        extra_x = self.extra(x)\n",
    "        output = self.conv1(x)\n",
    "        out = F.relu(self.bn1(output))\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        return F.relu(extra_x + out)\n",
    "\n",
    "class model4(nn.Module):\n",
    "    def __init__(self, num_of_classes: int, input_dimension: int, uses_attention: bool = True):\n",
    "        super(model4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = nn.Sequential(RestNetBasicBlock(64, 64, 1),\n",
    "                                    RestNetBasicBlock(64, 64, 1))\n",
    "\n",
    "        self.layer2 = nn.Sequential(RestNetDownBlock(64, 128, [2, 1]),\n",
    "                                    RestNetBasicBlock(128, 128, 1))\n",
    "\n",
    "        self.layer3 = nn.Sequential(RestNetDownBlock(128, 256, [2, 1]),\n",
    "                                    RestNetBasicBlock(256, 256, 1))\n",
    "\n",
    "        self.layer4 = nn.Sequential(RestNetDownBlock(256, 512, [2, 1]),\n",
    "                                    RestNetBasicBlock(512, 512, 1))\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "\n",
    "        self.fc = nn.Linear(512, num_of_classes)\n",
    "        if uses_attention:\n",
    "            print(\"Model with 2 attention modules.\")\n",
    "\n",
    "            ### build_softmax_module:       conv1d --> ReLU -->Softmax\n",
    "\n",
    "            ### AttentionBlock: build_softmax_module -->\n",
    "            self._attention_block_1 = AttentionBlock(64, int(input_dimension / 2), num_of_classes)\n",
    "            self._attention_block_2 = AttentionBlock(64, int(input_dimension / 2), num_of_classes)\n",
    "            self._attention_block_3 = AttentionBlock(128, int(input_dimension / 4), num_of_classes)\n",
    "            self._attention_block_4 = AttentionBlock(256, int(input_dimension / 8), num_of_classes)\n",
    "\n",
    "            self._classifier_confidence = build_classifier_confidence(512)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        self.loss = torch.nn.BCELoss()\n",
    "        self.uses_attention = uses_attention\n",
    "\n",
    "    def forward(self, x, y, infer):\n",
    "        global first_module_prediction, second_module_prediction, \\\n",
    "            third_module_prediction, fourth_module_prediction\n",
    "\n",
    "        z = self.conv1(x)\n",
    "        if self.uses_attention:\n",
    "            first_module_prediction = self._attention_block_1(z, y, infer)\n",
    "        z = self.layer1(z)\n",
    "        if self.uses_attention:\n",
    "            second_module_prediction = self._attention_block_2(z, y, infer)\n",
    "        z = self.layer2(z)\n",
    "#         print(z.shape)\n",
    "        if self.uses_attention:\n",
    "            third_module_prediction = self._attention_block_3(z, y, infer)\n",
    "        z = self.layer3(z)\n",
    "        if self.uses_attention:\n",
    "            fourth_module_prediction = self._attention_block_4(z, y, infer)\n",
    "        z = self.layer4(z)\n",
    "        z = self.avgpool(z)\n",
    "        z = z.reshape(x.shape[0], -1)\n",
    "        prediction = self.fc(z)\n",
    "        # print(prediction.shape)  #(10,5)\n",
    "        # a = z.view(z.shape[0], -1)\n",
    "        # b= self._classifier_confidence(z.view(z.shape[0], -1))\n",
    "        # print(b.shape) #(10,1)\n",
    "        # print(a.shape) #(10,512)\n",
    "        if self.uses_attention:\n",
    "            # print((self._classifier_confidence(z.view(z.shape[0], -1))).shape)\n",
    "            prediction *= self._classifier_confidence(z.view(z.shape[0], -1))\n",
    "        if self.uses_attention:\n",
    "            return f.softmax(prediction + first_module_prediction + second_module_prediction + \\\n",
    "                             third_module_prediction + fourth_module_prediction, dim=1)\n",
    "        return f.softmax(prediction, dim=1)\n",
    "\n",
    "model = model4(5,128)\n",
    "\n",
    "\n",
    "def train_network(x_train: np.ndarray, y_train: np.ndarray, model=model):\n",
    "    training_history = []\n",
    "    loss_history = []\n",
    "    training_time = []\n",
    "    for current_epoch in range(epochs):\n",
    "        torch.enable_grad()\n",
    "        model.train()\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        print(\"Epoch {}:\".format(current_epoch))\n",
    "        print(\"\\tTraining phase:\")\n",
    "\n",
    "        training_accuracies = []\n",
    "        losses = []\n",
    "        begin = time.time()\n",
    "\n",
    "        x_train_list = [x_train[i:i + batch_size] for i in range(0, len(x_train), batch_size)]\n",
    "        y_train_list = [y_train[i:i + batch_size] for i in range(0, len(y_train), batch_size)]\n",
    "\n",
    "        for x, y in tqdm(zip(x_train_list, y_train_list), total=len(x_train_list)):\n",
    "            x = torch.from_numpy(x.astype(\"float32\")).type(torch.cuda.FloatTensor)\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            y = torch.from_numpy(y.astype(\"float32\")).type(torch.cuda.LongTensor)\n",
    "            y = (torch.nn.functional.one_hot(y, num_classes=5)).type(torch.cuda.FloatTensor)\n",
    "            model.zero_grad()\n",
    "            model.optimizer.zero_grad()\n",
    "            out = model(x, y, infer=True)\n",
    "            loss = model.loss(out, y)\n",
    "            losses.append(loss.clone().detach().cpu().numpy())\n",
    "            accuracy = (torch.argmax(out, dim=1) == torch.argmax(y, dim=1)).sum().type(torch.cuda.DoubleTensor) / \\\n",
    "                       y.shape[0]\n",
    "            #             accuracy = (torch.argmax(out, dim=1) == y).sum().type(torch.cuda.DoubleTensor) / \\\n",
    "            #                        y.shape[0]\n",
    "            training_accuracies.append(accuracy.cpu().numpy())\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "\n",
    "        training_time.append(time.time() - begin)\n",
    "\n",
    "        loss_history.append(np.mean(losses))\n",
    "        training_history.append(np.mean(training_accuracies))\n",
    "\n",
    "        print(\"\\tLoss: {0} \".format(loss_history[-1]))\n",
    "        print(\"\\tTraining accuracy: {0} \".format(training_history[-1]))\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "        pickle.dump(training_history,\n",
    "                    open(os.path.join(output_dir, '2d' + \"_training_history.pkl\"), \"wb\"))\n",
    "\n",
    "        pickle.dump(loss_history, open(os.path.join(output_dir, '2d' + \"_loss_history.pkl\"), \"wb\"))\n",
    "        pickle.dump(training_time,\n",
    "                    open(os.path.join(output_dir, '2d' + \"_time_training.pkl\"), \"wb\"))\n",
    "\n",
    "        if current_epoch == 0 or (training_history[-1] > max(training_history[:-1])):\n",
    "            print(\"\\tSaving model...\")\n",
    "            torch.save(model, os.path.join(output_dir, '2d' + \"_model.pt\"))\n",
    "        if current_epoch > patience:\n",
    "            if max(training_history[:-patience]) > max(training_history[-patience:]):\n",
    "                print(\"\\tBail...\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,x_train,y_train):\n",
    "    \"\"\"\n",
    "    Method for running the experiments.\n",
    "\n",
    "    :param args: Parsed arguments.\n",
    "    :param selected_bands: Bands selected by the outlier detection algorithm.\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.to(device)\n",
    "    train_network(x_train=x_train, y_train=y_train, model=model)\n",
    "# train(model,x_img_train,y_img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def infer_network(x_test: np.ndarray, y_test: np.ndarray, model):\n",
    "    \"\"\"\n",
    "    Conduct inference on the trained model.\n",
    "\n",
    "    :param x_test: Samples for testing.\n",
    "    :param y_test: Labels for testing.\n",
    "    :param args: Parsed arguments.\n",
    "    :param input_size: Size of the initial band spectrum.\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    model = torch.load(os.path.join(output_dir, '2d' + \"_model.pt\"))\n",
    "    testing_accuracies = []\n",
    "    pres = []\n",
    "    labels = []\n",
    "\n",
    "    torch.no_grad()\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    print(\"\\tTesting:\")\n",
    "\n",
    "    begin = time.time()\n",
    "    x_test_list = [x_test[i:i + batch_size] for i in range(0, len(x_test), batch_size)]\n",
    "    y_test_list = [y_test[i:i + batch_size] for i in range(0, len(y_test), batch_size)]\n",
    "\n",
    "    for x, y in tqdm(zip(x_test_list, y_test_list), total=len(x_test_list)):\n",
    "        x = torch.from_numpy(x.astype(\"float32\")).type(torch.cuda.FloatTensor)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        y = torch.from_numpy(y.astype(\"float32\")).type(torch.cuda.LongTensor)\n",
    "        y = (torch.nn.functional.one_hot(y, num_classes=5)).type(torch.cuda.FloatTensor)\n",
    "        model.zero_grad()\n",
    "        accuracy = (torch.argmax(model(x, y, infer=True), dim=1) == torch.argmax(y, dim=1)).sum().type(\n",
    "            torch.cuda.DoubleTensor) / y.shape[0]\n",
    "        #         accuracy = (torch.argmax(model(x), dim=1) == torch.argmax(y, dim=1)).sum().type(torch.cuda.DoubleTensor) / y.shape[0]\n",
    "        testing_accuracies.append(accuracy.cpu().numpy())\n",
    "        pred1 = torch.argmax(model(x, y, infer=True), dim=1)\n",
    "        pres = np.append(pres, pred1.cpu().numpy())\n",
    "        y_t = torch.argmax(y, dim=1)\n",
    "        labels = np.append(labels, y_t.cpu().numpy())\n",
    "\n",
    "    testing_time = time.time() - begin\n",
    "    print(\"tesing_time:\", testing_time)\n",
    "    testing_accuracy = [np.mean(testing_accuracies)]\n",
    "    print(\"\\tTesting accuracy: {} \".format(testing_accuracy[0]))\n",
    "#     if model.uses_attention:\n",
    "#         heatmaps_per_class = model.get_heatmaps()\n",
    "#         pickle.dump(heatmaps_per_class,\n",
    "#                     open(os.path.join(output_dir, '2d' + \"_attention_bands.pkl\"), \"wb\"))\n",
    "\n",
    "#     pickle.dump(testing_accuracy,\n",
    "#                 open(os.path.join(output_dir, '2d' + \"_testing_accuracy.pkl\"), \"wb\"))\n",
    "#     pickle.dump(testing_time, open(os.path.join(output_dir, '2d' + \"_time_testing.pkl\"), \"wb\"))\n",
    "    cm = confusion_matrix(labels, pres)\n",
    "    Emotion_kinds = 5  # 这个数值是具体的分类数，大家可以自行修改\n",
    "\n",
    "    Pre = precision_score(labels, pres, average=None)\n",
    "    print('Pres:', np.mean(Pre))\n",
    "    Rec = recall_score(labels, pres, average=None)\n",
    "    print('Rec:', np.mean(Rec))\n",
    "    F1 = f1_score(labels, pres, average=None)\n",
    "    print(np.mean(F1))\n",
    "\n",
    "    # 显示数据\n",
    "#     plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "#     labels = ['N', 'E', 'B', 'L', 'M']  # 每种类别的标签\n",
    "#     # 在图中标注数量/概率信息\n",
    "#     thresh = cm.max() / 2  # 数值颜色阈值，如果数值超过这个，就颜色加深。\n",
    "#     for x in range(Emotion_kinds):\n",
    "#         for y in range(Emotion_kinds):\n",
    "#             # 注意这里的matrix[y, x]不是matrix[x, y]\n",
    "#             info = int(cm[y, x])\n",
    "#             plt.text(x, y, info,\n",
    "#                      verticalalignment='center',\n",
    "#                      horizontalalignment='center',\n",
    "#                      color=\"white\" if info > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()  # 保证图不重叠\n",
    "#     plt.yticks(range(Emotion_kinds), labels)\n",
    "#     plt.xticks(range(Emotion_kinds), labels, rotation=45)  # X轴字体倾斜45°\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTesting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [00:19<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesing_time: 19.2760591506958\n",
      "\tTesting accuracy: 0.916 \n",
      "Pres: 0.9154567773723992\n",
      "Rec: 0.916\n",
      "0.9151885618030677\n",
      "41.56687140464783\n"
     ]
    }
   ],
   "source": [
    "output_dir = r'E:\\2D_A_Result'\n",
    "batch_size=2\n",
    "start = time.time()\n",
    "infer_network(x_img_test,y_img_test,model)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
